{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device id(s) configuration.\n",
    "\n",
    "There are 3 options to configure devices for analysis.\n",
    "1. Single device id\n",
    "2. A list of device ids\n",
    "3. All devices associated with the API key configured in the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to analyse a single device, replace None with the device id (in quotes), e.g. \"DD1234567890\"\n",
    "DEVICE_ID = None \n",
    "\n",
    "# If you want to analyse a list of devices, place a csv file with the device id list (e.g. as exported from Django) in the `devices_collections` folder\n",
    "# and enter the filename here (in quotes), e.g. \"project_x_devices.csv\" \n",
    "# (make sure to set DEVICE_ID to None as it takes precedence)\n",
    "DEVICE_IDS_FILENAME = \"device_ids-20250225-062420.csv\" \n",
    "\n",
    "# If you want to analyse all devices associated with a device group, configure the API key of the device group in the .env file\n",
    "# and set the values of DEVICE_ID and DEVICE_IDS_FILENAME above to None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Period configuration\n",
    "\n",
    "Configure the time period to analyse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEZONE = \"Australia/Sydney\"         # The timezone the period is defined in\n",
    "START_DATE = \"2025-02-20\"             # Date string in the format <YYYY-MM-DD> in the target timezone\n",
    "END_DATE = \"2025-02-25\"               # Date string in the format <YYYY-MM-DD> in the target timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold configuration\n",
    "\n",
    "Configure the data completeness threshold under which a device is considered problematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_COMPLETENESS_THRESHOLD = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import pendulum\n",
    "import plotly.graph_objects as go\n",
    "from itables import show\n",
    "from itables import JavascriptFunction, JavascriptCode\n",
    "\n",
    "\n",
    "from config import AppConfig\n",
    "from api_clients import PublicApiClient\n",
    "from logger import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AppConfig(os.environ)\n",
    "logger: logging.Logger = get_logger(config)\n",
    "public_api_client = PublicApiClient(config.ENVIRONMENT, config.PUBLIC_API_KEY, config.PUBLIC_API_MAX_TPS, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_device_id(device_id: str, raise_error: bool = False) -> tuple[bool, str]:\n",
    "  \"\"\"\n",
    "  Returns True if the device ID is valid, False if not.\n",
    "  Simplified version based on lib_common\n",
    "  \"\"\"\n",
    "  DEVICE_ID_PATTERN = \"^[B-F]{1}[A-F0-9]{12}$\"\n",
    "  DEVICE_ID_REGEX = re.compile(DEVICE_ID_PATTERN)\n",
    "  # re.match won't detect trailing space in the device id, but re.fullmatch will.\n",
    "  if not DEVICE_ID_REGEX.fullmatch(device_id):\n",
    "      return False\n",
    "  return True\n",
    "\n",
    "# Determine devices to analyse\n",
    "devices: list[str] = []\n",
    "if DEVICE_ID is not None:\n",
    "  devices = [DEVICE_ID]\n",
    "elif DEVICE_IDS_FILENAME is not None:\n",
    "  # TODO: add checks for presence of file and data in the file\n",
    "  df = pd.read_csv(f'./devices_collections/{DEVICE_IDS_FILENAME}', header=None, names=['device_id'])\n",
    "  devices= df['device_id'].tolist()\n",
    "else:\n",
    "  # get all devices associated with API key\n",
    "  result, error = public_api_client.get_devices_list()\n",
    "  if error is not None:\n",
    "    logger.error(f'failed to load devices for API key: {error}')\n",
    "  else:\n",
    "    devices = result\n",
    "\n",
    "# filter out any invalid device ids\n",
    "devices =[d for d in devices if is_valid_device_id(d)]\n",
    "\n",
    "\n",
    "num_devices = len(devices)\n",
    "logger.info(f'found {num_devices} devices to analyse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine timestamps for requests\n",
    "time_start = pendulum.parse(START_DATE, tz=TIMEZONE)\n",
    "timestamp_start = time_start.int_timestamp\n",
    "\n",
    "time_end = pendulum.parse(END_DATE, tz=TIMEZONE)\n",
    "timestamp_end = time_end.int_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load device status for each device to exclude decommissioned devices\n",
    "# Issue: only user-apps-api exposes this and we can't use that because of different auth system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download LE data\n",
    "le_data = {}\n",
    "for index, device_id in enumerate(devices):\n",
    "  logger.info(f'Downloading LE data for device {index+1}/{num_devices} - {device_id}')\n",
    "  result, error = public_api_client.load_long_energy(device_id, timestamp_start, timestamp_end)\n",
    "  if error is not None:\n",
    "    logger.error(f'failed to load LE for device: {device_id}: {error}')\n",
    "  else:\n",
    "    le_data[device_id] = result\n",
    "\n",
    "logger.info(f'Successfully downloaded LE data for {len(le_data)}/{num_devices} devices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devices we couldn't download LE data for (included in devices list but not in LE dict)\n",
    "devices_with_le_data = list(le_data.keys())\n",
    "devices_without_le_data = [device_id for device_id in devices if device_id not in devices_with_le_data]\n",
    "\n",
    "devices_with_empty_le_data = [device_id for device_id, data in le_data.items() if len(data) == 0]\n",
    "\n",
    "# Determine expected number of intervals\n",
    "# Calculate the number of 5-minute intervals between the start and end timestamps using pendulum\n",
    "num_intervals_expected = int((time_end.diff(time_start).in_minutes()) // 5)\n",
    "\n",
    "# Devices with missing LE data\n",
    "# TODO: add alternative analysis based on timestamp and duration of interval (only works for intervals between existing intervals, i.e. need to handle missing intervals at start or end of period separately)\n",
    "# Could also just do a quick analysis to verify all intervals have a duration of 300s.\n",
    "devices_with_missing_le_data = {device_id: data for device_id, data in le_data.items() if len(data) < num_intervals_expected}\n",
    "\n",
    "# Devices not meeting data completeness threshold\n",
    "num_intervals_completeness_threshold = DATA_COMPLETENESS_THRESHOLD * num_intervals_expected // 100 # TODO: double check if this can result in off-by-one error\n",
    "devices_not_meeting_threshold = {device_id: data for device_id, data in le_data.items() if len(data) < num_intervals_completeness_threshold}\n",
    "\n",
    "# Devices with complete LE data\n",
    "devices_with_complete_le_data = {device_id: data for device_id, data in le_data.items() if len(data) == num_intervals_expected}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High level analysis\n",
    "\n",
    "le_data_df = pd.DataFrame({\n",
    "    'device_id': list(le_data.keys()),\n",
    "    'le_intervals': list(le_data.values()),\n",
    "    'num_intervals': [len(data) for data in le_data.values()]\n",
    "})\n",
    "\n",
    "le_data_df['num_intervals_expected'] = num_intervals_expected\n",
    "le_data_df['num_intervals_missing'] = le_data_df['num_intervals_expected'] - le_data_df['num_intervals']\n",
    "le_data_df['interval_completeness'] = le_data_df['num_intervals'] / le_data_df['num_intervals_expected']\n",
    "le_data_df['interval_missingness'] = 1 - le_data_df['interval_completeness']\n",
    "\n",
    "le_data_df = le_data_df.sort_values(by='interval_completeness')\n",
    "\n",
    "df_devices_table = le_data_df[['device_id', 'interval_completeness', 'num_intervals_missing']].copy()\n",
    "df_devices_table['interval_completeness'] = df_devices_table['interval_completeness'] * 100\n",
    "\n",
    "parameters = [{\n",
    "  'start_time': time_start,\n",
    "  'end_time': time_end,\n",
    "  'num_expected_intervals': num_intervals_expected,\n",
    "  \n",
    "}]\n",
    "\n",
    "top_level_stats = [{\n",
    "  'num_devices': num_devices,\n",
    "  'overall_completeness': le_data_df['num_intervals'].sum() / (num_devices * num_intervals_expected) * 100,\n",
    "  'devices_under_threshold': len(devices_not_meeting_threshold),\n",
    "  'devices_with_missing_intervals': len(devices_with_missing_le_data),\n",
    "  'devices_without_data': len(devices_with_empty_le_data),\n",
    "  'devices_with_failed_retrieval': len(devices_without_le_data),\n",
    "  'devices_with_complete_data': len(devices_with_complete_le_data),\n",
    "}]\n",
    "\n",
    "df_parameters = pd.DataFrame.from_dict(parameters)\n",
    "df_stats = pd.DataFrame.from_dict(top_level_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform interval data\n",
    "\n",
    "def flatten_arrays(item: dict) -> dict:\n",
    "    \"\"\" flatten each element of arrays to their own key. Other types of values are left untouched.\n",
    "    e.g. {key: [value0, value1, ...]} becomes {key_0: value0, key_1: value1, ...}.            \n",
    "    \"\"\"\n",
    "    flattened = {}\n",
    "    for key, value in item.items():\n",
    "      if isinstance(value, list):\n",
    "        for idx, subvalue in enumerate(value):\n",
    "          flattened[f\"{key}_{idx}\"] = subvalue\n",
    "      else:\n",
    "        flattened[key] = value\n",
    "    return flattened\n",
    "\n",
    "\n",
    "# Create an empty DataFrame\n",
    "intervals = []\n",
    "\n",
    "for index, row in le_data_df.iterrows():\n",
    "    # Perform any necessary operations on each row\n",
    "    # For example, you could print the device_id and interval_completeness\n",
    "    device_id = row['device_id']\n",
    "    data = row['le_intervals']\n",
    "    for item in data:\n",
    "        row = flatten_arrays(item)\n",
    "        row[\"device_id\"] = device_id\n",
    "        intervals.append(row)\n",
    "\n",
    "df_intervals = pd.DataFrame.from_dict(intervals) \n",
    "# Reorder the columns to move 'device_id', 'timestamp', and 'duration' to the front\n",
    "columns_order = ['device_id', 'timestamp', 'duration'] + [col for col in df_intervals.columns if col not in ['device_id', 'timestamp', 'duration']]\n",
    "df_intervals = df_intervals[columns_order]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By-day analysis\n",
    "\n",
    "df_intervals['datetime'] = pd.to_datetime(df_intervals['timestamp'], unit='s').dt.tz_localize('UTC').dt.tz_convert(TIMEZONE)\n",
    "\n",
    "df_daily_counts = df_intervals.groupby(['device_id', df_intervals['datetime'].dt.date]).size().reset_index(name='entry_count')\n",
    "df_daily_counts.columns = ['device_id', 'date', 'num_intervals']\n",
    "df_daily_counts['date'] = pd.to_datetime(df_daily_counts['date']).dt.tz_localize(TIMEZONE)\n",
    "\n",
    "# Add in missing intervals (set to 0)\n",
    "date_range = pd.date_range(start=time_start, end=time_end.subtract(seconds=1), freq='D')\n",
    "all_device_dates = pd.MultiIndex.from_product([devices, date_range], names=['device_id', 'date'])\n",
    "\n",
    "missing_entries = all_device_dates.difference(df_daily_counts.set_index(['device_id', 'date']).index)\n",
    "missing_df = pd.DataFrame(list(missing_entries), columns=['device_id', 'date'])\n",
    "missing_df['num_intervals'] = 0\n",
    "df_daily_counts = pd.concat([df_daily_counts, missing_df], ignore_index=True)\n",
    "\n",
    "num_intervals_expected_daily = 24 * 12\n",
    "df_daily_counts['missing_intervals'] = num_intervals_expected_daily - df_daily_counts['num_intervals']\n",
    "df_daily_counts['interval_completeness'] = 100 * df_daily_counts['num_intervals'] / num_intervals_expected_daily\n",
    "# Move interval_completeness column to 3rd column\n",
    "\n",
    "df_daily_counts['date'] = pd.to_datetime(df_daily_counts['date']).dt.date\n",
    "\n",
    "\n",
    "\n",
    "cols = df_daily_counts.columns.tolist()\n",
    "cols.insert(2, cols.pop(cols.index('interval_completeness')))\n",
    "df_daily_counts = df_daily_counts[cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High level stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(df_parameters)\n",
    "show(df_stats, \n",
    "     columnDefs= [\n",
    "        { \"targets\": [1], \"createdCell\": JavascriptFunction(\n",
    "                f\"\"\"\n",
    "                    function (td, cellData, rowData, row, col) {{\n",
    "                        if (cellData < {DATA_COMPLETENESS_THRESHOLD}) {{\n",
    "                            $(td).css('color', 'red')\n",
    "                        }}\n",
    "                    }}\n",
    "                \"\"\"\n",
    "        )},\n",
    "        {\n",
    "            \"targets\": [1],\n",
    "            \"render\": JavascriptCode(\"$.fn.dataTable.render.number(',', '.', 2, '', '%')\"),\n",
    "        }\n",
    "    ],)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per device stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(df_devices_table, \n",
    "     columnDefs= [\n",
    "        { \"targets\": [1], \"createdCell\": JavascriptFunction(\n",
    "                f\"\"\"\n",
    "                    function (td, cellData, rowData, row, col) {{\n",
    "                        if (cellData < {DATA_COMPLETENESS_THRESHOLD}) {{\n",
    "                            $(td).css('color', 'red')\n",
    "                        }}\n",
    "                    }}\n",
    "                \"\"\"\n",
    "        )},\n",
    "        {\n",
    "            \"targets\": [1],\n",
    "            \"render\": JavascriptCode(\"$.fn.dataTable.render.number(',', '.', 2, '', '%')\"),\n",
    "        }\n",
    "    ],\n",
    "    showIndex=False,\n",
    "    buttons=[\"copyHtml5\", \"csvHtml5\", \"excelHtml5\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per device per day stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(df_daily_counts, \n",
    "     columnDefs= [\n",
    "        { \"targets\": [2], \"createdCell\": JavascriptFunction(\n",
    "                f\"\"\"\n",
    "                    function (td, cellData, rowData, row, col) {{\n",
    "                        if (cellData < {DATA_COMPLETENESS_THRESHOLD}) {{\n",
    "                            $(td).css('color', 'red')\n",
    "                        }}\n",
    "                    }}\n",
    "                \"\"\"\n",
    "        )},\n",
    "        {\n",
    "            \"targets\": [2],\n",
    "            \"render\": JavascriptCode(\"$.fn.dataTable.render.number(',', '.', 2, '', '%')\"),\n",
    "        }\n",
    "    ],\n",
    "    showIndex=False,\n",
    "    pageLength=20,\n",
    "    buttons=[\"copyHtml5\", \"csvHtml5\", \"excelHtml5\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: For large datasets, running this cell may result in memory issues.\n",
    "\n",
    "show(df_intervals, \n",
    "     showIndex=False,\n",
    "     maxBytes=0,\n",
    "     pageLength=20,\n",
    "     buttons=[\"copyHtml5\", \"csvHtml5\", \"excelHtml5\"]\n",
    "     )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "le-completeness-analysis-XK_cgeV8-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
